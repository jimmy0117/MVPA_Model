{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Dense, LayerNormalization\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default hyperparameters\n",
    "NEURONS = 300\n",
    "HIDDEN_LAYERS = 3\n",
    "\n",
    "def create_DNN(input_shape, neurons = NEURONS, hidden_layers = HIDDEN_LAYERS, learning_rate = 0.001, verbose=0):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_dim=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for i in range(hidden_layers-1):\n",
    "        model.add(Dense(neurons))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) # categorical_crossentropy\n",
    "\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_df.shape : (1000, 28)\n",
      "source_df.columns : Index(['ID', 'Sex', 'Age', 'Disease category', 'Narrow pitch range',\n",
      "       'Decreased volume', 'Fatigue', 'Dryness', 'Lumping', 'heartburn',\n",
      "       'Choking', 'Eye dryness', 'PND', 'Smoking', 'PPD', 'Drinking',\n",
      "       'frequency', 'Diurnal pattern', 'Onset of dysphonia ', 'Noise at work',\n",
      "       'Occupational vocal demand', 'Diabetes', 'Hypertension', 'CAD',\n",
      "       'Head and Neck Cancer', 'Head injury', 'CVA',\n",
      "       'Voice handicap index - 10'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 讀取訓練資料集表單\n",
    "fileName=\"./dataset/Training_Dataset/Training_Dataset/training_datalist.csv\"\n",
    "source_df = pd.read_csv(fileName)\n",
    "\n",
    "print(\"source_df.shape :\", source_df.shape)\n",
    "print(\"source_df.columns :\", source_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medical_data_proccessing(df):\n",
    "    medical_col = ['Sex', 'Age', 'Narrow pitch range',\n",
    "                'Decreased volume', 'Fatigue', 'Dryness', 'Lumping', 'heartburn',\n",
    "                'Choking', 'Eye dryness', 'PND', 'Smoking', 'PPD', 'Drinking',\n",
    "                'frequency', 'Diurnal pattern', 'Onset of dysphonia ', 'Noise at work',\n",
    "                'Occupational vocal demand', 'Diabetes', 'Hypertension', 'CAD',\n",
    "                'Head and Neck Cancer', 'Head injury', 'CVA',\n",
    "                'Voice handicap index - 10', 'Disease category']\n",
    "    \n",
    "    # 選定要訓練預測的類別\n",
    "    df = df.loc[df['Disease category'].isin([1, 2, 3,4,5]), medical_col]\n",
    "\n",
    "    # 將性別編碼0,1\n",
    "    df['Sex'] = df['Sex'] - 1\n",
    "\n",
    "    # 將空值填0\n",
    "    df['PPD'] = df['PPD'].fillna(0)\n",
    "    df['Voice handicap index - 10'] = df['Voice handicap index - 10'].fillna(0)\n",
    "\n",
    "    # 正規化過大的數值\n",
    "    df['Age'] = df['Age'] / 50\n",
    "    df['Voice handicap index - 10'] = df['Voice handicap index - 10'] / 40\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease category in training_df : [1 2 3 5 4]\n",
      "training_df col : Index(['Sex', 'Age', 'Narrow pitch range', 'Decreased volume', 'Fatigue',\n",
      "       'Dryness', 'Lumping', 'heartburn', 'Choking', 'Eye dryness', 'PND',\n",
      "       'Smoking', 'PPD', 'Drinking', 'frequency', 'Diurnal pattern',\n",
      "       'Onset of dysphonia ', 'Noise at work', 'Occupational vocal demand',\n",
      "       'Diabetes', 'Hypertension', 'CAD', 'Head and Neck Cancer',\n",
      "       'Head injury', 'CVA', 'Voice handicap index - 10', 'Disease category'],\n",
      "      dtype='object')\n",
      "training_df shape : (1000, 27)\n"
     ]
    }
   ],
   "source": [
    "source_df = medical_data_proccessing(source_df)\n",
    "\n",
    "print(\"Disease category in training_df :\", source_df['Disease category'].unique())\n",
    "print(\"training_df col :\", source_df.columns)\n",
    "print(\"training_df shape :\", source_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_df shape : (800, 27) , test_df shape : (200, 27)\n"
     ]
    }
   ],
   "source": [
    "training_df, test_df = train_test_split(source_df, test_size=0.2, random_state=333)\n",
    "\n",
    "print(\"training_df shape :\", training_df.shape, \", test_df shape :\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape : (800, 31)\n",
      "x_train.shape, y_train.shape : (800, 26) (800, 5)\n",
      "y_train.columns : ['c1', 'c2', 'c3', 'c4', 'c5']\n"
     ]
    }
   ],
   "source": [
    "# 訓練資料標記轉換\n",
    "training_data = training_df.iloc[:, :-1]\n",
    "training_data['c1'] = training_df['Disease category'].map({1:1, 2:0, 3:0, 4:0, 5:0})\n",
    "training_data['c2'] = training_df['Disease category'].map({1:0, 2:1, 3:0, 4:0, 5:0})\n",
    "training_data['c3'] = training_df['Disease category'].map({1:0, 2:0, 3:1, 4:0, 5:0})\n",
    "training_data['c4'] = training_df['Disease category'].map({1:0, 2:0, 3:0, 4:1, 5:0})\n",
    "training_data['c5'] = training_df['Disease category'].map({1:0, 2:0, 3:0, 4:0, 5:1})\n",
    "\n",
    "print(\"training_data.shape :\", training_data.shape)\n",
    "\n",
    "x_train = training_data.iloc[:, :-5]\n",
    "y_train = training_data.iloc[:, -5:]\n",
    "print(\"x_train.shape, y_train.shape :\", x_train.shape, y_train.shape)\n",
    "print(\"y_train.columns :\", y_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape : (200, 31)\n",
      "x_val.shape, y_val.shape : (200, 26) (200, 5)\n",
      "y_val.columns : ['c1', 'c2', 'c3', 'c4', 'c5']\n"
     ]
    }
   ],
   "source": [
    "# 驗證資料標記轉換\n",
    "test_data = test_df.iloc[:, :-1]\n",
    "test_data['c1'] = test_df['Disease category'].map({1:1, 2:0, 3:0, 4:0, 5:0})\n",
    "test_data['c2'] = test_df['Disease category'].map({1:0, 2:1, 3:0, 4:0, 5:0})\n",
    "test_data['c3'] = test_df['Disease category'].map({1:0, 2:0, 3:1, 4:0, 5:0})\n",
    "test_data['c4'] = test_df['Disease category'].map({1:0, 2:0, 3:0, 4:1, 5:0})\n",
    "test_data['c5'] = test_df['Disease category'].map({1:0, 2:0, 3:0, 4:0, 5:1})\n",
    "\n",
    "print(\"test_data.shape :\", test_data.shape)\n",
    "\n",
    "x_val = test_data.iloc[:, :-5]\n",
    "y_val = test_data.iloc[:, -5:]\n",
    "print(\"x_val.shape, y_val.shape :\", x_val.shape, y_val.shape)\n",
    "print(\"y_val.columns :\", y_val.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 300)               8100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 300)               90300     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 300)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               90300     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 300)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 1505      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 190,205\n",
      "Trainable params: 190,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_DNN(input_shape = x_train.shape[1], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 2s 46ms/step - loss: 1.2100 - accuracy: 0.5325 - val_loss: 0.9337 - val_accuracy: 0.6650\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1.0186 - accuracy: 0.6175 - val_loss: 0.8456 - val_accuracy: 0.6800\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.9381 - accuracy: 0.6300 - val_loss: 0.7950 - val_accuracy: 0.7200\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.8819 - accuracy: 0.6500 - val_loss: 0.7816 - val_accuracy: 0.7250\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.8192 - accuracy: 0.6875 - val_loss: 0.7686 - val_accuracy: 0.7150\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.8108 - accuracy: 0.6825 - val_loss: 0.7807 - val_accuracy: 0.7100\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7698 - accuracy: 0.6900 - val_loss: 0.8172 - val_accuracy: 0.6750\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.7385 - accuracy: 0.7212 - val_loss: 0.7606 - val_accuracy: 0.7200\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.7188 - val_loss: 0.8982 - val_accuracy: 0.6950\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6402 - accuracy: 0.7550 - val_loss: 0.8090 - val_accuracy: 0.7250\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6227 - accuracy: 0.7675 - val_loss: 0.8704 - val_accuracy: 0.7300\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6070 - accuracy: 0.7600 - val_loss: 0.9246 - val_accuracy: 0.7050\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7912 - val_loss: 0.8735 - val_accuracy: 0.7250\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.8150 - val_loss: 0.8853 - val_accuracy: 0.7250\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4590 - accuracy: 0.8275 - val_loss: 0.9925 - val_accuracy: 0.6850\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.8425 - val_loss: 0.9744 - val_accuracy: 0.6800\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.3720 - accuracy: 0.8587 - val_loss: 1.0047 - val_accuracy: 0.7100\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8637 - val_loss: 1.0461 - val_accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "MODEL_SAVE_NAME = \"AI_CUP_medical_sample_model\"\n",
    "\n",
    "train_results = model.fit(x_train, y_train, batch_size=None, epochs=100, \n",
    "                              callbacks=[EarlyStopping(monitor='val_loss', patience=10, mode='auto'),\n",
    "                                         ModelCheckpoint(MODEL_SAVE_NAME+\".h5\", save_best_only=True)], \n",
    "                              validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter kernelspec list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Topic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
